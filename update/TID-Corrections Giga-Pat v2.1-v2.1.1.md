# üìò TID (Technical Implementation Document)
## Corrections Giga-Pat v2.1 ‚Üí v2.1.1

**Date** : 2025-11-12
**Projet** : giga-pat
**Branche** : `claude/analyze-giga-pat-project-011CV3mgMUCcBtmsy5vpni1J`
**Objectif** : Corriger les incoh√©rences et erreurs identifi√©es en 4 phases

---

## üéØ INSTRUCTIONS G√âN√âRALES

### R√®gles strictes d'ex√©cution :
1. ‚úÖ Suivre l'ordre exact des phases (1 ‚Üí 2 ‚Üí 3 ‚Üí 4)
2. ‚úÖ Suivre l'ordre exact des t√¢ches dans chaque phase
3. ‚úÖ Lire le fichier complet AVANT toute modification
4. ‚úÖ Utiliser Edit tool (jamais Write sur fichiers existants)
5. ‚úÖ Copier-coller EXACTEMENT les blocs AVANT/APR√àS
6. ‚úÖ Valider chaque t√¢che avec les crit√®res fournis
7. ‚úÖ Commiter apr√®s chaque phase compl√©t√©e
8. ‚ùå NE PAS improviser de modifications non document√©es
9. ‚ùå NE PAS modifier de fichiers non list√©s
10. ‚ùå NE PAS sauter d'√©tapes

### Structure de chaque t√¢che :
```
T√ÇCHE X.Y : [Titre]
‚îú‚îÄ‚îÄ Fichier : [chemin exact]
‚îú‚îÄ‚îÄ Action : [description pr√©cise]
‚îú‚îÄ‚îÄ AVANT : [code √† remplacer]
‚îú‚îÄ‚îÄ APR√àS : [nouveau code]
‚îú‚îÄ‚îÄ Validation : [comment v√©rifier]
‚îî‚îÄ‚îÄ Rollback : [comment annuler si erreur]
```

---

# üö® PHASE 1 : CORRECTIONS CRITIQUES

**Objectif** : Corriger 4 issues critiques (s√©curit√© + conformit√© interface)
**Dur√©e estim√©e** : 1-2 heures
**Commit message** : `fix(critical): Security patches and parser interface compliance`

---

## T√ÇCHE 1.1 : Corriger BitstackTransactionHistoryParser - strategy_name

**Fichier** : `/home/user/giga-pat/tools/parsers/bitstack/transaction_history.py`

**Action** : Convertir l'attribut de classe `strategy_name` en propri√©t√© `@property`

**AVANT** (ligne 37) :
```python
    strategy_name = "bitstack.transaction_history.v2025"
```

**APR√àS** :
```python
    @property
    def strategy_name(self) -> str:
        """Identifiant unique de la strat√©gie de parsing."""
        return "bitstack.transaction_history.v2025"
```

**Validation** :
```bash
python3 -c "from tools.parsers.bitstack import BitstackTransactionHistoryParser; p = BitstackTransactionHistoryParser(); assert p.strategy_name == 'bitstack.transaction_history.v2025'; print('‚úì strategy_name OK')"
```

**Rollback** : Restaurer la ligne 37 originale

---

## T√ÇCHE 1.2 : Corriger BitstackTransactionHistoryParser - can_parse()

**Fichier** : `/home/user/giga-pat/tools/parsers/bitstack/transaction_history.py`

**Action** : Modifier signature et retour de `can_parse()` pour retourner `float` au lieu de `bool`

**AVANT** (lignes 50-74) :
```python
    def can_parse(self, file_path: str, metadata: Dict[str, Any]) -> bool:
        """
        V√©rifie si le fichier peut √™tre pars√© par ce parser.

        Crit√®res:
        - Fichier CSV
        - Pattern [BIT] - *.csv
        - Contient les colonnes attendues
        """
        path = Path(file_path)

        # V√©rification du pattern de nom
        if not path.name.startswith('[BIT]') or path.suffix.lower() != '.csv':
            return False

        # V√©rification des colonnes
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                headers = reader.fieldnames or []
                required = ['Type', 'Date', 'Montant re√ßu', 'Monnaie ou jeton re√ßu']
                return all(col in headers for col in required)
        except Exception as e:
            self.logger.warning(f"Impossible de v√©rifier les colonnes: {e}")
            return False
```

**APR√àS** :
```python
    def can_parse(self, file_path: str, metadata: Dict[str, Any]) -> float:
        """
        V√©rifie si le fichier peut √™tre pars√© par ce parser.

        Crit√®res:
        - Fichier CSV
        - Pattern [BIT] - *.csv
        - Contient les colonnes attendues

        Returns:
            float: Score de confiance (0.0 = impossible, 1.0 = certain)
        """
        path = Path(file_path)

        # V√©rification du pattern de nom
        if not path.name.startswith('[BIT]') or path.suffix.lower() != '.csv':
            return 0.0

        # V√©rification des colonnes
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                headers = reader.fieldnames or []
                required = ['Type', 'Date', 'Montant re√ßu', 'Monnaie ou jeton re√ßu']
                return 1.0 if all(col in headers for col in required) else 0.0
        except Exception as e:
            self.logger.warning(f"Impossible de v√©rifier les colonnes: {e}")
            return 0.0
```

**Validation** :
```bash
python3 -c "from tools.parsers.bitstack import BitstackTransactionHistoryParser; p = BitstackTransactionHistoryParser(); result = p.can_parse('test.csv', {}); assert isinstance(result, float); assert 0.0 <= result <= 1.0; print(f'‚úì can_parse() returns float: {result}')"
```

**Rollback** : Restaurer les lignes 50-74 originales

---

## T√ÇCHE 1.3 : Corriger BitstackTransactionHistoryParser - validate()

**Fichier** : `/home/user/giga-pat/tools/parsers/bitstack/transaction_history.py`

**Action** : Modifier signature et retour de `validate()` pour retourner `List[str]` au lieu de `bool`

**AVANT** (lignes 173-205) :
```python
    def validate(self, parsed_data: Dict[str, Any]) -> bool:
        """
        Valide les donn√©es pars√©es.

        Crit√®res:
        - Structure correcte (dict avec 'positions')
        - Au moins une position
        - Solde BTC >= 0 (coh√©rence des transactions)
        """
        if not parsed_data:
            self.logger.error("Aucune donn√©e pars√©e")
            return False

        # Check for dict structure
        if not isinstance(parsed_data, dict):
            self.logger.error(f"Format incorrect: attendu dict, obtenu {type(parsed_data)}")
            return False

        positions = parsed_data.get('positions', [])
        if not positions:
            self.logger.error("Aucune position trouv√©e")
            return False

        if len(positions) != 1:
            self.logger.error(f"Attendu 1 position r√©sum√©e, obtenu {len(positions)}")
            return False

        btc_qty = positions[0].get('quantite', 0)
        if btc_qty < 0:
            self.logger.error(f"Solde BTC n√©gatif: {btc_qty}")
            return False

        return True
```

**APR√àS** :
```python
    def validate(self, parsed_data: Dict[str, Any]) -> List[str]:
        """
        Valide les donn√©es pars√©es.

        Crit√®res:
        - Structure correcte (dict avec 'positions')
        - Au moins une position
        - Solde BTC >= 0 (coh√©rence des transactions)

        Returns:
            List[str]: Liste des anomalies d√©tect√©es (vide si tout est valide)
        """
        anomalies = []

        if not parsed_data:
            anomalies.append("Aucune donn√©e pars√©e")
            return anomalies

        # Check for dict structure
        if not isinstance(parsed_data, dict):
            anomalies.append(f"Format incorrect: attendu dict, obtenu {type(parsed_data)}")
            return anomalies

        positions = parsed_data.get('positions', [])
        if not positions:
            anomalies.append("Aucune position trouv√©e")
            return anomalies

        if len(positions) != 1:
            anomalies.append(f"Attendu 1 position r√©sum√©e, obtenu {len(positions)}")

        btc_qty = positions[0].get('quantite', 0)
        if btc_qty < 0:
            anomalies.append(f"Solde BTC n√©gatif: {btc_qty}")

        return anomalies
```

**Validation** :
```bash
python3 -c "from tools.parsers.bitstack import BitstackTransactionHistoryParser; p = BitstackTransactionHistoryParser(); result = p.validate({}); assert isinstance(result, list); assert len(result) > 0; print(f'‚úì validate() returns List[str]: {result}')"
```

**Rollback** : Restaurer les lignes 173-205 originales

---

## T√ÇCHE 1.4 : Ajouter import List dans BitstackTransactionHistoryParser

**Fichier** : `/home/user/giga-pat/tools/parsers/bitstack/transaction_history.py`

**Action** : V√©rifier que `List` est bien import√© de `typing` (ligne 27)

**AVANT** (ligne 27) :
```python
from typing import Dict, List, Any, Optional
```

**APR√àS** : (Pas de changement si d√©j√† pr√©sent, sinon ajouter `List`)
```python
from typing import Dict, List, Any, Optional
```

**Validation** :
```bash
grep "from typing import.*List" /home/user/giga-pat/tools/parsers/bitstack/transaction_history.py
```

**Rollback** : N/A (import d√©j√† pr√©sent)

---

## T√ÇCHE 1.5 : S√©curit√© - Remplacer MD5 par SHA-256

**Fichier** : `/home/user/giga-pat/tools/cache_manager.py`

**Action** : Remplacer `hashlib.md5()` par `hashlib.sha256()`

**AVANT** (lignes 42-46) :
```python
    def _compute_file_hash(self, file_path: Path) -> str:
        """Calcule le hash MD5 d'un fichier."""
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                hasher.update(chunk)
        return hasher.hexdigest()
```

**APR√àS** :
```python
    def _compute_file_hash(self, file_path: Path) -> str:
        """Calcule le hash SHA-256 d'un fichier pour v√©rification d'int√©grit√©."""
        hasher = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                hasher.update(chunk)
        return hasher.hexdigest()
```

**Validation** :
```bash
python3 -c "import hashlib; h = hashlib.sha256(); h.update(b'test'); assert len(h.hexdigest()) == 64; print('‚úì SHA-256 OK')"
```

**Rollback** : Restaurer `md5()` si n√©cessaire (mais d√©conseill√©)

---

## T√ÇCHE 1.6 : S√©curit√© - Validation Path Traversal

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : Ajouter validation de s√©curit√© pour les chemins de fichiers

**AVANT** (lignes 196-203) :
```python
            # R√©cup√©rer le parser via le registry
            filepath = sources_dir / compte_def["source_file"]
            if not filepath.exists():
                self.logger.warning(f"‚ö†Ô∏è  Fichier introuvable: {filepath}")
                continue

            parser_name = compte_def.get("parser_strategy")
            if not parser_name:
```

**APR√àS** :
```python
            # R√©cup√©rer le parser via le registry
            filepath = sources_dir / compte_def["source_file"]

            # Validation de s√©curit√© : emp√™cher path traversal
            try:
                resolved_path = filepath.resolve()
                sources_resolved = sources_dir.resolve()
                if not str(resolved_path).startswith(str(sources_resolved)):
                    self.logger.error(f"üö® Path traversal d√©tect√©: {filepath}")
                    raise ValueError(f"Tentative d'acc√®s √† un fichier hors de {sources_dir}")
            except (ValueError, OSError) as e:
                self.logger.error(f"üö® Erreur de s√©curit√© sur le chemin: {e}")
                continue

            if not filepath.exists():
                self.logger.warning(f"‚ö†Ô∏è  Fichier introuvable: {filepath}")
                continue

            parser_name = compte_def.get("parser_strategy")
            if not parser_name:
```

**Validation** :
```bash
python3 -c "from pathlib import Path; base = Path('/home/user/giga-pat/sources').resolve(); malicious = (base / '../../../etc/passwd').resolve(); assert not str(malicious).startswith(str(base)); print('‚úì Path traversal detection OK')"
```

**Rollback** : Supprimer le bloc try-except ajout√©

---

## T√ÇCHE 1.7 : S√©curit√© - Validation Path Traversal (Pattern multi-fichiers)

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : Ajouter validation de s√©curit√© pour les patterns multi-fichiers

**AVANT** (lignes 253-258 environ, chercher dans `_parse_compte_multi_files`) :
```python
            for matched_file in matched_files:
                file_path = Path(matched_file)
                if not file_path.exists():
                    self.logger.warning(f"‚ö†Ô∏è  Fichier ignor√© (introuvable): {file_path}")
                    continue
```

**APR√àS** :
```python
            for matched_file in matched_files:
                file_path = Path(matched_file)

                # Validation de s√©curit√© : emp√™cher path traversal
                try:
                    resolved_path = file_path.resolve()
                    sources_resolved = self.sources_dir.resolve()
                    if not str(resolved_path).startswith(str(sources_resolved)):
                        self.logger.error(f"üö® Path traversal d√©tect√©: {file_path}")
                        continue
                except (ValueError, OSError) as e:
                    self.logger.error(f"üö® Erreur de s√©curit√© sur le chemin: {e}")
                    continue

                if not file_path.exists():
                    self.logger.warning(f"‚ö†Ô∏è  Fichier ignor√© (introuvable): {file_path}")
                    continue
```

**Validation** : M√™me que T√ÇCHE 1.6

**Rollback** : Supprimer le bloc try-except ajout√©

---

## T√ÇCHE 1.8 : Standardiser version - main.py

**Fichier** : `/home/user/giga-pat/main.py`

**Action** : Changer version de `v1.0.0` √† `v2.1.0`

**AVANT** (ligne 51) :
```python
‚ïë     PATRIMOINE ANALYZER v1.0.0                ‚ïë
```

**APR√àS** :
```python
‚ïë     PATRIMOINE ANALYZER v2.1.0                ‚ïë
```

**Validation** :
```bash
grep "v2.1.0" /home/user/giga-pat/main.py
```

**Rollback** : Restaurer `v1.0.0`

---

## T√ÇCHE 1.9 : Standardiser version - config/config.yaml

**Fichier** : `/home/user/giga-pat/config/config.yaml`

**Action** : Changer version de `2.0.0` √† `2.1.0`

**AVANT** (ligne 3) :
```yaml
  version: "2.0.0"  # Architecture manifest-driven + parsers pluggables
```

**APR√àS** :
```yaml
  version: "2.1.0"  # Architecture homog√®ne + custodian unifi√© + multi-file parsing avec cache
```

**Validation** :
```bash
grep 'version: "2.1.0"' /home/user/giga-pat/config/config.yaml
```

**Rollback** : Restaurer `2.0.0`

---

## T√ÇCHE 1.10 : Standardiser version - PRD.md

**Fichier** : `/home/user/giga-pat/PRD.md`

**Action** : Changer version de `2.0.0` √† `2.1.0` et mise √† jour description

**AVANT** (lignes 3-9) :
```markdown
**Version** : 2.0.0
**Date** : Novembre 2025
**Auteur** : Sp√©cifications pour Claude Code

## üÜï Version 2.0 (Novembre 2025)

Cette version introduit une architecture **manifest-driven** avec **parsers pluggables** pour am√©liorer la robustesse et l'extensibilit√© du syst√®me de parsing.
```

**APR√àS** :
```markdown
**Version** : 2.1.0
**Date** : Novembre 2025
**Auteur** : Sp√©cifications pour Claude Code

## üÜï Version 2.1 (Novembre 2025)

Cette version compl√®te l'architecture **manifest-driven** avec **custodian unifi√©**, **sections manuelles** et **parsing multi-fichiers avec cache intelligent**.
```

**Validation** :
```bash
grep "Version\*\* : 2.1.0" /home/user/giga-pat/PRD.md
```

**Rollback** : Restaurer `2.0.0`

---

## T√ÇCHE 1.11 : Standardiser version - README.md

**Fichier** : `/home/user/giga-pat/README.md`

**Action** : Changer "Version 2.0" √† "Version 2.1"

**AVANT** (ligne 5) :
```markdown
**Version 2.0** - Architecture manifest-driven avec parsers pluggables
```

**APR√àS** :
```markdown
**Version 2.1** - Architecture homog√®ne avec custodian unifi√© et parsing multi-fichiers
```

**Validation** :
```bash
grep "Version 2.1" /home/user/giga-pat/README.md
```

**Rollback** : Restaurer `Version 2.0`

---

## T√ÇCHE 1.12 : Standardiser version - config/risks.yaml

**Fichier** : `/home/user/giga-pat/config/risks.yaml`

**Action** : Changer version de `2.0.0` √† `2.1.0`

**AVANT** (ligne 28) :
```yaml
  version: "2.0.0"
```

**APR√àS** :
```yaml
  version: "2.1.0"
```

**Validation** :
```bash
grep 'version: "2.1.0"' /home/user/giga-pat/config/risks.yaml | head -1
```

**Rollback** : Restaurer `2.0.0`

---

## T√ÇCHE 1.13 : Standardiser version - tools/__init__.py

**Fichier** : `/home/user/giga-pat/tools/__init__.py`

**Action** : Changer `__version__` de `1.0.0` √† `2.1.0`

**AVANT** (ligne 5, environ) :
```python
__version__ = "1.0.0"
```

**APR√àS** :
```python
__version__ = "2.1.0"
```

**Validation** :
```bash
python3 -c "import sys; sys.path.insert(0, '/home/user/giga-pat'); from tools import __version__; assert __version__ == '2.1.0'; print(f'‚úì tools.__version__ = {__version__}')"
```

**Rollback** : Restaurer `1.0.0`

---

## VALIDATION PHASE 1

Ex√©cuter ces commandes dans l'ordre :

```bash
# 1. Test imports et interface BitstackParser
python3 << 'EOF'
from tools.parsers.bitstack import BitstackTransactionHistoryParser
p = BitstackTransactionHistoryParser()

# Test strategy_name
assert hasattr(p, 'strategy_name')
assert p.strategy_name == "bitstack.transaction_history.v2025"
print("‚úì strategy_name OK")

# Test can_parse retourne float
result = p.can_parse('/tmp/test.csv', {})
assert isinstance(result, float)
assert 0.0 <= result <= 1.0
print(f"‚úì can_parse() returns float: {result}")

# Test validate retourne List[str]
anomalies = p.validate({})
assert isinstance(anomalies, list)
assert all(isinstance(a, str) for a in anomalies)
print(f"‚úì validate() returns List[str]: {len(anomalies)} anomalies")

print("\n‚úÖ BitstackParser interface CONFORME")
EOF

# 2. Test versions
python3 << 'EOF'
import yaml
from pathlib import Path

# config.yaml
with open('/home/user/giga-pat/config/config.yaml') as f:
    config = yaml.safe_load(f)
    assert config['project']['version'] == "2.1.0", f"config.yaml version: {config['project']['version']}"
    print("‚úì config.yaml version 2.1.0")

# risks.yaml
with open('/home/user/giga-pat/config/risks.yaml') as f:
    risks = yaml.safe_load(f)
    assert risks['risk_settings']['version'] == "2.1.0"
    print("‚úì risks.yaml version 2.1.0")

# tools.__init__
from tools import __version__
assert __version__ == "2.1.0"
print(f"‚úì tools.__version__ = {__version__}")

print("\n‚úÖ Toutes les versions sont √† 2.1.0")
EOF

# 3. Test s√©curit√© hash
python3 << 'EOF'
from tools.cache_manager import CacheManager
from pathlib import Path
import tempfile

# Cr√©er fichier temporaire
with tempfile.NamedTemporaryFile(delete=False) as f:
    f.write(b"test content")
    temp_path = Path(f.name)

cm = CacheManager(Path("/tmp/test_cache"))
hash_result = cm._compute_file_hash(temp_path)

# SHA-256 produit 64 caract√®res hexad√©cimaux
assert len(hash_result) == 64, f"Hash length: {len(hash_result)} (expected 64 for SHA-256)"
print(f"‚úì Hash SHA-256 OK: {hash_result[:16]}...")

temp_path.unlink()
print("\n‚úÖ CacheManager utilise SHA-256")
EOF

echo ""
echo "‚úÖ‚úÖ‚úÖ PHASE 1 VALID√âE ‚úÖ‚úÖ‚úÖ"
```

Si tous les tests passent, passer au commit :

```bash
git add -A
git commit -m "fix(critical): Security patches and parser interface compliance

- BitstackParser: Convert strategy_name to @property
- BitstackParser: can_parse() returns float (0.0-1.0) instead of bool
- BitstackParser: validate() returns List[str] instead of bool
- Security: Replace MD5 with SHA-256 in cache_manager
- Security: Add path traversal validation in normalizer
- Version: Standardize all versions to 2.1.0

Related issues: #1-4 (critical)"
```

---

# üî∂ PHASE 2 : CORRECTIONS IMPORTANTES

**Objectif** : Corriger 5 issues importantes (s√©curit√© r√©seau + gestion erreurs)
**Dur√©e estim√©e** : 2-3 heures
**Commit message** : `fix(high): Network security, error handling and resilient parsing`

---

## T√ÇCHE 2.1 : Impl√©menter Session HTTP avec retry

**Fichier** : `/home/user/giga-pat/tools/utils/web_research.py`

**Action** : Remplacer `requests.get()` par `self.session.get()` avec retry

**AVANT** (lignes 31-40, dans `__init__`) :
```python
    def __init__(self, config: Dict[str, Any]):
        """
        Initialise le chercheur web.

        Args:
            config: Configuration (api_key, timeout, etc.)
        """
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 10)
        self.api_url = "https://api.search.brave.com/res/v1/web/search"
        self.logger = logging.getLogger(__name__)
```

**APR√àS** :
```python
    def __init__(self, config: Dict[str, Any]):
        """
        Initialise le chercheur web.

        Args:
            config: Configuration (api_key, timeout, etc.)
        """
        self.api_key = config.get("api_key")
        self.timeout = config.get("timeout", 10)
        self.api_url = "https://api.search.brave.com/res/v1/web/search"
        self.logger = logging.getLogger(__name__)

        # Session HTTP avec pooling de connexions
        self.session = requests.Session()
        self.session.verify = True  # SSL verification explicite
```

**Validation** :
```bash
python3 -c "from tools.utils.web_research import WebResearcher; wr = WebResearcher({'api_key': 'test'}); assert hasattr(wr, 'session'); assert wr.session.verify is True; print('‚úì Session HTTP OK')"
```

**Rollback** : Supprimer les lignes ajout√©es

---

## T√ÇCHE 2.2 : Remplacer requests.get par session.get

**Fichier** : `/home/user/giga-pat/tools/utils/web_research.py`

**Action** : Utiliser `self.session.get()` au lieu de `requests.get()`

**AVANT** (lignes 174-179, chercher la ligne avec `requests.get`) :
```python
            response = requests.get(
                self.api_url,
                headers=headers,
                params=params,
                timeout=self.timeout
            )
```

**APR√àS** :
```python
            response = self.session.get(
                self.api_url,
                headers=headers,
                params=params,
                timeout=self.timeout,
                verify=True  # SSL verification explicite
            )
```

**Validation** : Tests manuels apr√®s toutes les modifications de la phase

**Rollback** : Restaurer `requests.get`

---

## T√ÇCHE 2.3 : Sanitizer les erreurs API (ne pas exposer cl√©)

**Fichier** : `/home/user/giga-pat/tools/utils/web_research.py`

**Action** : Filtrer la cl√© API des messages d'erreur

**AVANT** (lignes 182-190, bloc except apr√®s requests.get) :
```python
        except requests.RequestException as e:
            self.logger.error(f"Erreur lors de la recherche web: {e}")
            return {
                "results": [],
                "total_results": 0,
                "error": str(e)
            }
```

**APR√àS** :
```python
        except requests.RequestException as e:
            # Sanitize error message - ne jamais exposer l'API key
            error_msg = str(e)
            if self.api_key and self.api_key in error_msg:
                error_msg = error_msg.replace(self.api_key, "[REDACTED]")

            self.logger.error(f"Erreur lors de la recherche web: {error_msg}")
            return {
                "results": [],
                "total_results": 0,
                "error": "Erreur de connexion √† l'API (d√©tails en logs)"
            }
```

**Validation** :
```bash
python3 << 'EOF'
# Test que l'API key n'appara√Æt pas dans les erreurs
msg = "Error with key BSA81KxMOB0qrs"
api_key = "BSA81KxMOB0qrs"
sanitized = msg.replace(api_key, "[REDACTED]") if api_key in msg else msg
assert "[REDACTED]" in sanitized
assert api_key not in sanitized
print("‚úì API key sanitization OK")
EOF
```

**Rollback** : Restaurer le bloc except original

---

## T√ÇCHE 2.4 : Am√©liorer gestion exceptions - normalizer.py (1/3)

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : Remplacer `except Exception` par exceptions sp√©cifiques dans `_parse_compte_single_file`

**AVANT** (lignes 213-214, chercher dans `_parse_compte_single_file`) :
```python
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du parsing de {filepath}: {e}")
            return None
```

**APR√àS** :
```python
        except ParsingError as e:
            self.logger.error(f"‚ùå Erreur de parsing de {filepath}: {e}")
            return None
        except (OSError, IOError) as e:
            self.logger.error(f"‚ùå Erreur d'acc√®s au fichier {filepath}: {e}")
            return None
        except Exception as e:
            self.logger.error(f"‚ùå Erreur inattendue lors du parsing de {filepath}: {e}")
            self.logger.exception("Stack trace:")
            return None
```

**Validation** : V√©rification visuelle du code

**Rollback** : Restaurer le bloc except original

---

## T√ÇCHE 2.5 : Am√©liorer gestion exceptions - analyzer.py (2/3)

**Fichier** : `/home/user/giga-pat/tools/analyzer.py`

**Action** : Am√©liorer exception handling dans la m√©thode `analyze()`

**AVANT** (lignes 72-74, dans `analyze()`) :
```python
        except Exception as e:
            self.logger.error(f"Erreur lors de l'analyse: {e}")
            raise
```

**APR√àS** :
```python
        except (FileNotFoundError, IOError) as e:
            self.logger.error(f"Erreur d'acc√®s aux fichiers de configuration: {e}")
            raise
        except KeyError as e:
            self.logger.error(f"Donn√©e manquante dans le patrimoine d'entr√©e: {e}")
            raise
        except Exception as e:
            self.logger.error(f"Erreur inattendue lors de l'analyse: {e}")
            self.logger.exception("Stack trace compl√®te:")
            raise
```

**Validation** : V√©rification visuelle du code

**Rollback** : Restaurer le bloc except original

---

## T√ÇCHE 2.6 : Am√©liorer gestion exceptions - generator.py (3/3)

**Fichier** : `/home/user/giga-pat/tools/generator.py`

**Action** : Am√©liorer exception handling dans la m√©thode `generate()`

**AVANT** (chercher le bloc try/except principal dans `generate()`, probablement vers lignes 860-862) :
```python
        except Exception as e:
            self.logger.error(f"Erreur lors de la g√©n√©ration: {e}")
            raise
```

**APR√àS** :
```python
        except (FileNotFoundError, IOError) as e:
            self.logger.error(f"Erreur d'acc√®s au template ou fichier de sortie: {e}")
            raise
        except KeyError as e:
            self.logger.error(f"Champ manquant dans les donn√©es d'analyse: {e}")
            self.logger.exception("D√©tails de l'erreur:")
            raise
        except Exception as e:
            self.logger.error(f"Erreur inattendue lors de la g√©n√©ration: {e}")
            self.logger.exception("Stack trace compl√®te:")
            raise
```

**Validation** : V√©rification visuelle du code

**Rollback** : Restaurer le bloc except original

---

## T√ÇCHE 2.7 : Parsing r√©silient - continuer si un parser √©choue

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : Ne pas arr√™ter toute la normalisation si un seul compte √©choue

**Instruction** : Cette modification est d√©j√† en place (le code retourne `None` et continue). V√©rifier que c'est bien le cas.

**Validation** :
```bash
# Chercher les return None dans les blocs except
grep -A 2 "except.*Error" /home/user/giga-pat/tools/normalizer.py | grep "return None"
```

**Si la validation √©choue** : Ajouter `return None` dans les blocs except qui l√®vent des exceptions

**Rollback** : N/A (d√©j√† correct)

---

## VALIDATION PHASE 2

Ex√©cuter ces commandes :

```bash
# 1. Test Session HTTP
python3 << 'EOF'
from tools.utils.web_research import WebResearcher

wr = WebResearcher({'api_key': 'test_key_12345'})

# V√©rifier session existe
assert hasattr(wr, 'session'), "Session HTTP manquante"
assert wr.session.verify is True, "SSL verification non activ√©e"

print("‚úì Session HTTP avec SSL verification OK")
print(f"‚úì Session type: {type(wr.session)}")

print("\n‚úÖ WebResearcher configuration correcte")
EOF

# 2. Test sanitization API key
python3 << 'EOF'
api_key = "BSA81KxMOB0qrs_BtDxDoSthWZfNuPc"
error_msg = f"Authentication failed with key {api_key}"

# Sanitize
if api_key in error_msg:
    error_msg = error_msg.replace(api_key, "[REDACTED]")

assert api_key not in error_msg
assert "[REDACTED]" in error_msg
print(f"‚úì API key sanitization: {error_msg}")

print("\n‚úÖ Sanitization des erreurs OK")
EOF

# 3. V√©rifier imports pour exceptions sp√©cifiques
python3 << 'EOF'
from tools.parsers.base_parser import ParsingError
from tools.normalizer import Normalizer
from tools.analyzer import Analyzer
from tools.generator import Generator

print("‚úì Tous les imports OK")
print("\n‚úÖ Gestion d'erreurs am√©lior√©e")
EOF

echo ""
echo "‚úÖ‚úÖ‚úÖ PHASE 2 VALID√âE ‚úÖ‚úÖ‚úÖ"
```

Si tous les tests passent, commiter :

```bash
git add -A
git commit -m "fix(high): Network security, error handling and resilient parsing

- WebResearcher: Use requests.Session() for connection pooling
- WebResearcher: Explicit SSL verification (verify=True)
- WebResearcher: Sanitize error messages to prevent API key exposure
- Normalizer/Analyzer/Generator: Specific exception handling instead of bare Exception
- Parsing: Continue processing other accounts if one fails (already implemented)

Related issues: #5-9 (high priority)"
```

---

# üü° PHASE 3 : REFACTORING

**Objectif** : Am√©liorer la qualit√© du code (pas de bugs critiques)
**Dur√©e estim√©e** : 4-6 heures (optionnel si temps limit√©)
**Commit message** : `refactor: Cache management, validation and code organization`

---

## T√ÇCHE 3.1 : Impl√©menter limite de taille du cache

**Fichier** : `/home/user/giga-pat/tools/cache_manager.py`

**Action** : Ajouter m√©thode de nettoyage du cache avec limite de taille

**APR√àS la m√©thode `clear_cache()` (apr√®s ligne 140 environ), AJOUTER** :

```python
    def enforce_cache_limit(self, max_size_mb: int = 100) -> None:
        """
        Nettoie le cache si la taille d√©passe la limite.

        Strat√©gie: Suppression des fichiers les plus anciens (LRU).

        Args:
            max_size_mb: Taille maximale du cache en Mo
        """
        if not self.cache_dir.exists():
            return

        # Calculer taille totale
        total_size = 0
        cache_files = []

        for cache_file in self.cache_dir.glob("*.json"):
            size = cache_file.stat().st_size
            mtime = cache_file.stat().st_mtime
            total_size += size
            cache_files.append({
                'path': cache_file,
                'size': size,
                'mtime': mtime
            })

        total_size_mb = total_size / (1024 * 1024)

        if total_size_mb <= max_size_mb:
            self.logger.info(f"Cache size: {total_size_mb:.2f} MB (under limit: {max_size_mb} MB)")
            return

        # Trier par date de modification (plus ancien en premier)
        cache_files.sort(key=lambda x: x['mtime'])

        # Supprimer les plus anciens jusqu'√† passer sous la limite
        removed_count = 0
        for cache_file in cache_files:
            if total_size_mb <= max_size_mb:
                break

            cache_file['path'].unlink()
            total_size_mb -= cache_file['size'] / (1024 * 1024)
            removed_count += 1

        self.logger.info(f"Cache cleanup: removed {removed_count} files, new size: {total_size_mb:.2f} MB")
```

**Validation** :
```bash
python3 << 'EOF'
from tools.cache_manager import CacheManager
from pathlib import Path

cm = CacheManager(Path("/tmp/test_cache_limit"))
assert hasattr(cm, 'enforce_cache_limit')
print("‚úì enforce_cache_limit() method exists")
EOF
```

**Rollback** : Supprimer la m√©thode ajout√©e

---

## T√ÇCHE 3.2 : Appeler enforce_cache_limit dans le Normalizer

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : Appeler `enforce_cache_limit()` apr√®s la normalisation

**Dans la m√©thode `normalize()`, AVANT le return final (chercher `return output_data`), AJOUTER** :

```python
        # Nettoyer le cache si n√©cessaire (limite: 100 MB)
        self.cache_manager.enforce_cache_limit(max_size_mb=100)
```

**Validation** : Tests end-to-end apr√®s toutes les modifications

**Rollback** : Supprimer la ligne ajout√©e

---

## T√ÇCHE 3.3 : Valider manifest.json AVANT traitement

**Fichier** : `/home/user/giga-pat/tools/normalizer.py`

**Action** : D√©placer la validation du sch√©ma au tout d√©but

**AVANT** (dans `normalize()`, chercher l'appel √† `_validate_manifest_schema`) :
La validation est probablement appel√©e apr√®s certains traitements.

**APR√àS** : S'assurer que cette ligne est IMM√âDIATEMENT apr√®s le chargement du manifest :

```python
        # Charger manifest
        manifest_path = self.sources_dir / self.config["input_file"]
        with open(manifest_path, "r", encoding="utf-8") as f:
            manifest = json.load(f)

        # VALIDATION IMM√âDIATE avant tout traitement
        validation_errors = self._validate_manifest_schema(manifest)
        if validation_errors:
            error_msg = "\n".join([f"  - {err}" for err in validation_errors])
            self.logger.error(f"‚ùå Manifest invalide:\n{error_msg}")
            raise ValueError(f"manifest.json invalide. Erreurs:\n{error_msg}")
```

**Validation** : V√©rifier l'ordre du code

**Rollback** : Restaurer l'ordre original

---

## T√ÇCHE 3.4 : Extraire constantes des magic numbers - risk_analyzer.py

**Fichier** : `/home/user/giga-pat/tools/utils/risk_analyzer.py`

**Action** : Extraire les seuils en constantes nomm√©es

**AU D√âBUT du fichier, APR√àS les imports, AJOUTER** :

```python
# === CONSTANTES DE SEUILS DE RISQUE ===

# Concentration Assurance-Vie (%)
AV_CONCENTRATION_CRITIQUE = 25  # Au-del√† de 25% du patrimoine en AV = Critique
AV_CONCENTRATION_ELEVEE = 15    # 15-25% = √âlev√©
AV_CONCENTRATION_MODEREE = 10   # 10-15% = Mod√©r√©

# Concentration √©tablissement unique (%)
ETABLISSEMENT_CONCENTRATION_CRITIQUE = 70
ETABLISSEMENT_CONCENTRATION_ELEVEE = 50

# Concentration g√©ographique (%)
GEO_CONCENTRATION_CRITIQUE = 90
GEO_CONCENTRATION_ELEVEE = 80

# Liquidit√© (%)
LIQUIDITE_CRITIQUE = 5   # Moins de 5% de liquidit√©s = Critique
LIQUIDITE_FAIBLE = 10    # 5-10% = Risque mod√©r√©
```

**Validation** : V√©rifier que les constantes sont d√©finies

**Rollback** : Supprimer le bloc ajout√©

---

## T√ÇCHE 3.5 : Utiliser les constantes dans risk_analyzer.py

**Fichier** : `/home/user/giga-pat/tools/utils/risk_analyzer.py`

**Action** : Remplacer les magic numbers par les constantes

**EXEMPLE** : Chercher `if pct_av >= 25` et remplacer par `if pct_av >= AV_CONCENTRATION_CRITIQUE`

**Faire les remplacements suivants** (chercher et remplacer) :
- `>= 25` dans le contexte AV ‚Üí `>= AV_CONCENTRATION_CRITIQUE`
- `>= 15` dans le contexte AV ‚Üí `>= AV_CONCENTRATION_ELEVEE`
- `>= 10` dans le contexte AV ‚Üí `>= AV_CONCENTRATION_MODEREE`
- `>= 70` pour √©tablissement ‚Üí `>= ETABLISSEMENT_CONCENTRATION_CRITIQUE`
- `>= 50` pour √©tablissement ‚Üí `>= ETABLISSEMENT_CONCENTRATION_ELEVEE`

**Validation** :
```bash
grep -n "AV_CONCENTRATION_CRITIQUE\|ETABLISSEMENT_CONCENTRATION" /home/user/giga-pat/tools/utils/risk_analyzer.py
```

**Rollback** : Restaurer les nombres originaux

---

## VALIDATION PHASE 3

```bash
# 1. Test limite cache
python3 << 'EOF'
from tools.cache_manager import CacheManager
from pathlib import Path
import json
import tempfile

# Cr√©er cache temporaire
temp_dir = Path(tempfile.mkdtemp())
cm = CacheManager(temp_dir)

# Cr√©er plusieurs fichiers cache
for i in range(5):
    cache_file = temp_dir / f"test_{i}.json"
    cache_file.write_text(json.dumps({"data": "x" * 100000}))  # ~100KB each

# V√©rifier m√©thode existe
assert hasattr(cm, 'enforce_cache_limit')

# Appliquer limite (devrait supprimer certains fichiers)
cm.enforce_cache_limit(max_size_mb=0.3)  # 300KB max

remaining = list(temp_dir.glob("*.json"))
print(f"‚úì Cache cleanup: {len(remaining)} files remaining (5 ‚Üí {len(remaining)})")

# Cleanup
import shutil
shutil.rmtree(temp_dir)

print("\n‚úÖ Cache size management OK")
EOF

# 2. Test constantes risk_analyzer
python3 << 'EOF'
import sys
sys.path.insert(0, '/home/user/giga-pat')

# V√©rifier que les constantes existent
from tools.utils.risk_analyzer import (
    AV_CONCENTRATION_CRITIQUE,
    AV_CONCENTRATION_ELEVEE,
    ETABLISSEMENT_CONCENTRATION_CRITIQUE
)

assert AV_CONCENTRATION_CRITIQUE == 25
assert AV_CONCENTRATION_ELEVEE == 15
assert ETABLISSEMENT_CONCENTRATION_CRITIQUE == 70

print("‚úì Risk thresholds constants OK")
print(f"  AV_CONCENTRATION_CRITIQUE = {AV_CONCENTRATION_CRITIQUE}%")
print(f"  AV_CONCENTRATION_ELEVEE = {AV_CONCENTRATION_ELEVEE}%")

print("\n‚úÖ Constants extraction OK")
EOF

echo ""
echo "‚úÖ‚úÖ‚úÖ PHASE 3 VALID√âE ‚úÖ‚úÖ‚úÖ"
```

Si tous les tests passent :

```bash
git add -A
git commit -m "refactor: Cache management, validation and code organization

- CacheManager: Add enforce_cache_limit() with LRU eviction (100MB max)
- Normalizer: Call cache cleanup after processing
- Normalizer: Validate manifest.json BEFORE any processing
- RiskAnalyzer: Extract magic numbers to named constants

Related issues: #10-15 (medium priority)"
```

---

# üîµ PHASE 4 : QUALIT√â & DOCUMENTATION

**Objectif** : Am√©liorer tests, docs, type hints
**Dur√©e estim√©e** : 6-8 heures (optionnel)
**Commit message** : `docs(quality): Improve type hints, docstrings and test coverage`

---

## ‚ö†Ô∏è PHASE 4 : TRAVAUX EXTENSIFS

Cette phase n√©cessite beaucoup de travail et peut √™tre diff√©r√©e.

### T√¢ches principales :

1. **Ajouter type hints manquants** (~100 fonctions)
2. **Standardiser docstrings** (style Google)
3. **Cr√©er tests manquants** :
   - `tests/test_cache_manager.py`
   - `tests/test_crypto_price_api.py`
   - Tests d'int√©gration end-to-end
4. **Configurer mypy** et corriger les erreurs
5. **Nettoyer TODOs** dans `project_generator.py`
6. **Ajuster niveaux de logs** (debug ‚Üí info/warning)

### Strat√©gie recommand√©e :

**Option A** : Faire progressivement sur plusieurs sessions
**Option B** : Cr√©er des issues GitHub pour chaque sous-t√¢che
**Option C** : D√©l√©guer √† plusieurs d√©veloppeurs

### Validation Phase 4 (quand compl√©t√©e) :

```bash
# 1. Type checking
mypy tools/ --ignore-missing-imports

# 2. Test coverage
pytest tests/ --cov=tools --cov-report=term-missing

# 3. Code quality
pylint tools/ --disable=C0301,C0103

# 4. V√©rifier docstrings
pydocstyle tools/ --convention=google
```

---

# üìã CHECKLIST FINALE

Apr√®s avoir compl√©t√© toutes les phases souhait√©es :

## ‚úÖ Phase 1 (Critique) - OBLIGATOIRE
- [ ] BitstackParser conforme √† BaseParser
- [ ] Toutes les versions √† 2.1.0
- [ ] Path traversal validation en place
- [ ] SHA-256 au lieu de MD5
- [ ] Tests Phase 1 passent
- [ ] Commit Phase 1 effectu√©

## ‚úÖ Phase 2 (Importante) - FORTEMENT RECOMMAND√âE
- [ ] Session HTTP avec pooling
- [ ] SSL verification explicite
- [ ] API key sanitization
- [ ] Exceptions sp√©cifiques
- [ ] Parsing r√©silient v√©rifi√©
- [ ] Tests Phase 2 passent
- [ ] Commit Phase 2 effectu√©

## ‚úÖ Phase 3 (Refactoring) - RECOMMAND√âE
- [ ] Cache size management
- [ ] Validation pr√©coce manifest
- [ ] Constantes au lieu de magic numbers
- [ ] Tests Phase 3 passent
- [ ] Commit Phase 3 effectu√©

## ‚úÖ Phase 4 (Qualit√©) - OPTIONNELLE
- [ ] Type hints ajout√©s
- [ ] Docstrings standardis√©es
- [ ] Tests manquants cr√©√©s
- [ ] Mypy configur√©
- [ ] TODOs r√©solus
- [ ] Coverage > 70%
- [ ] Commit Phase 4 effectu√©

## ‚úÖ Push final
- [ ] Tous les commits effectu√©s
- [ ] Tests locaux OK
- [ ] Push vers remote : `git push -u origin claude/analyze-giga-pat-project-011CV3mgMUCcBtmsy5vpni1J`

---

# üöÄ COMMANDES DE D√âMARRAGE

Pour ex√©cuter ce TID, commence par :

```bash
# 1. V√©rifier la branche
git status
git branch --show-current

# 2. S'assurer d'√™tre √† jour
git fetch origin
git status

# 3. Commencer Phase 1 T√¢che 1.1
echo "üöÄ D√âBUT PHASE 1 - CORRECTIONS CRITIQUES"
```

Puis ex√©cute **une t√¢che √† la fois**, dans l'ordre exact du TID.

---

**FIN DU TID**

Ce document contient toutes les instructions pour corriger le projet giga-pat de mani√®re syst√©matique et sans improvisation.
