#!/usr/bin/env python3
"""
G√©n√©rateur automatique du projet Patrimoine Analyzer

‚ö†Ô∏è ATTENTION: Ce fichier est un SCAFFOLD/TEMPLATE pour g√©n√©rer l'arborescence initiale du projet.
Ce n'est PAS du code de production. Les impl√©mentations r√©elles se trouvent dans:
- tools/normalizer.py (parsing et normalisation)
- tools/analyzer.py (analyse et risques)
- tools/generator.py (g√©n√©ration HTML)

Ce script g√©n√®re des fichiers templates avec des PLACEHOLDERS qui doivent √™tre remplac√©s
par les impl√©mentations r√©elles.

Usage:
    python project_generator.py

Note: Ce script n'est utile QUE pour cr√©er un nouveau projet depuis z√©ro.
      Pour un projet existant, n'ex√©cutez PAS ce script.
"""

import os
from pathlib import Path

def create_directory_structure():
    """Cr√©e l'arborescence des r√©pertoires"""
    directories = [
        "sources",
        "templates",
        "generated",
        "logs",
        "config",
        "tools",
        "tools/utils",
        "tests"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"‚úì Cr√©√© : {directory}/")
    
    # Fichiers .gitkeep pour r√©pertoires vides
    for empty_dir in ["sources", "generated", "logs"]:
        (Path(empty_dir) / ".gitkeep").touch()

def create_file(filepath, content):
    """Cr√©e un fichier avec son contenu"""
    Path(filepath).write_text(content, encoding='utf-8')
    print(f"‚úì Cr√©√© : {filepath}")

def generate_project():
    """G√©n√®re tous les fichiers du projet"""
    
    print("\n" + "="*60)
    print("üöÄ G√âN√âRATION DU PROJET PATRIMOINE ANALYZER")
    print("="*60 + "\n")
    
    # 1. Structure de r√©pertoires
    print("üìÅ Cr√©ation de l'arborescence...")
    create_directory_structure()
    
    # 2. requirements.txt
    print("\nüì¶ Cr√©ation requirements.txt...")
    create_file("requirements.txt", """# Core
python>=3.10

# Data processing
pandas>=2.0.0
numpy>=1.24.0

# File parsing
pdfplumber>=0.10.0
PyPDF2>=3.0.0
openpyxl>=3.1.0

# HTML/Web
beautifulsoup4>=4.12.0
lxml>=4.9.0

# API
anthropic>=0.25.0
requests>=2.31.0

# Config
pyyaml>=6.0

# Utils
python-dateutil>=2.8.0
""")

    # 3. .gitignore
    print("üìù Cr√©ation .gitignore...")
    create_file(".gitignore", """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Fichiers g√©n√©r√©s
generated/
logs/

# Donn√©es sensibles
sources/
!sources/.gitkeep

# Configuration locale
.env
*.local.yaml

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
""")

    # 4. config/config.yaml
    print("‚öôÔ∏è  Cr√©ation config/config.yaml...")
    create_file("config/config.yaml", """project:
  name: "Patrimoine Analyzer"
  version: "1.0.0"

paths:
  sources: "sources/"
  templates: "templates/"
  generated: "generated/"
  logs: "logs/"

normalizer:
  input_file: "patrimoine.md"
  output_file: "patrimoine_input.json"
  date_format: "ISO8601"

analyzer:
  input_file: "patrimoine_input.json"
  output_file: "patrimoine_analysis.json"
  web_research:
    enabled: true
    max_queries: 50
    timeout_seconds: 30
    retry_count: 3
  risk_thresholds:
    concentration_etablissement_critique: 50
    concentration_etablissement_eleve: 30
    concentration_juridiction_critique: 80
    concentration_juridiction_eleve: 60
    liquidite_critique: 5000
    liquidite_faible: 15000

generator:
  input_file: "patrimoine_analysis.json"
  template_file: "rapport_template.html"
  output_prefix: "rapport_"
  date_format: "%Y%m%d_%H%M%S"

logging:
  level: "INFO"
  format: "[%(asctime)s] %(levelname)s: %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
""")

    # 5. config/research_prompts.yaml
    print("‚öôÔ∏è  Cr√©ation config/research_prompts.yaml...")
    create_file("config/research_prompts.yaml", """# Prompts personnalis√©s pour recherches web

prompts:
  loi_sapin_2:
    sujet: "Loi Sapin 2 - Article 21 HCSF"
    queries:
      - "Loi Sapin 2 blocage assurance-vie 2025"
      - "HCSF article 21 conditions application"
      - "assurance-vie gel temporaire crise bancaire"
      - "article L. 612-33 code mon√©taire financier"

  fiscalite_epargne:
    sujet: "Fiscalit√© √©pargne 2025-2026"
    queries:
      - "projet loi finances 2026 fiscalit√© √©pargne"
      - "PFU flat tax √©volution 2025"
      - "assurance-vie fiscalit√© r√©forme"
      - "PEA fiscalit√© modification 2025"

  marches_actions:
    sujet: "Contexte march√©s actions 2025"
    queries:
      - "pr√©visions march√©s actions 2025 2026"
      - "volatilit√© march√©s financiers risques"
      - "correction boursi√®re probabilit√© analyse"
""")

    # 6. tools/__init__.py
    print("üõ†Ô∏è  Cr√©ation tools/__init__.py...")
    create_file("tools/__init__.py", """\"\"\"
Patrimoine Analyzer - Modules d'analyse
\"\"\"

__version__ = "1.0.0"
""")

    # 7. tools/utils/__init__.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/__init__.py...")
    create_file("tools/utils/__init__.py", """\"\"\"
Modules utilitaires
\"\"\"
""")

    # 8. tools/normalizer.py
    print("üõ†Ô∏è  Cr√©ation tools/normalizer.py...")
    create_file("tools/normalizer.py", """\"\"\"
Module de normalisation des fichiers sources
\"\"\"

import json
import logging
from pathlib import Path
from datetime import datetime
from tools.utils.file_parser import FileParser


class PatrimoineNormalizer:
    \"\"\"Normalise les fichiers sources en JSON structur√©\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.file_parser = FileParser()
        
    def normalize(self) -> dict:
        \"\"\"Point d'entr√©e principal de normalisation\"\"\"
        self.logger.info("D√©but normalisation...")
        
        # 1. Parse patrimoine.md
        self.logger.info("Lecture patrimoine.md...")
        patrimoine_data = self._parse_patrimoine_md()
        
        # 2. Load referenced files
        self.logger.info(f"Parsing {len(patrimoine_data.get('sources_files', []))} fichiers sources...")
        self._load_source_files(patrimoine_data)
        
        # 3. Calculate totals
        self.logger.info("Calcul totaux par cat√©gorie...")
        self._calculate_totals(patrimoine_data)
        
        # 4. Validate
        self.logger.info("Validation donn√©es...")
        self._validate(patrimoine_data)
        
        # 5. Save JSON
        output_path = Path(self.config["paths"]["generated"]) / self.config["normalizer"]["output_file"]
        self.logger.info(f"Sauvegarde {output_path}...")
        self._save_json(patrimoine_data, output_path)
        
        self.logger.info("‚úì Normalisation termin√©e")
        return patrimoine_data
    
    def _parse_patrimoine_md(self) -> dict:
        \"\"\"Parse le fichier patrimoine.md\"\"\"
        md_path = Path(self.config["paths"]["sources"]) / self.config["normalizer"]["input_file"]
        
        if not md_path.exists():
            raise FileNotFoundError(f"Fichier patrimoine.md introuvable : {md_path}")
        
        content = md_path.read_text(encoding='utf-8')
        
        # Structure de base
        data = {
            "meta": {
                "version": "1.0.0",
                "generated_at": datetime.now().isoformat(),
                "source_file": str(md_path)
            },
            "profil": {},
            "patrimoine": {
                "financier": {"total": 0, "etablissements": []},
                "crypto": {"total": 0, "plateformes": []},
                "metaux_precieux": {"total": 0},
                "immobilier": {"total": 0, "biens": []}
            },
            "sources_files": []
        }
        
        # Parsing basique (√† am√©liorer selon structure r√©elle)
        self.logger.info(f"Fichier patrimoine.md charg√© ({len(content.splitlines())} lignes)")
        
        return data
    
    def _load_source_files(self, data: dict):
        \"\"\"Charge les fichiers sources r√©f√©renc√©s\"\"\"
        # PLACEHOLDER: Impl√©menter parsing des fichiers CSV/PDF
        pass
    
    def _calculate_totals(self, data: dict):
        \"\"\"Calcule les totaux r√©cursifs\"\"\"
        # Financier
        total_financier = sum(e.get("total", 0) for e in data["patrimoine"]["financier"]["etablissements"])
        data["patrimoine"]["financier"]["total"] = total_financier
        
        self.logger.debug(f"Patrimoine financier total : {total_financier:,.0f} ‚Ç¨")
    
    def _validate(self, data: dict):
        \"\"\"Valide la coh√©rence des donn√©es\"\"\"
        # PLACEHOLDER: Ajouter validations
        self.logger.info("‚úì Validation OK")
    
    def _save_json(self, data: dict, output_path: Path):
        \"\"\"Sauvegarde le JSON normalis√©\"\"\"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
""")

    # 9. tools/analyzer.py
    print("üõ†Ô∏è  Cr√©ation tools/analyzer.py...")
    create_file("tools/analyzer.py", """\"\"\"
Module d'analyse du patrimoine
\"\"\"

import json
import logging
from pathlib import Path
from datetime import datetime
from tools.utils.web_research import WebResearcher
from tools.utils.risk_analyzer import RiskAnalyzer
from tools.utils.recommendations import Recommender
from tools.utils.stress_tester import StressTester


class PatrimoineAnalyzer:
    \"\"\"Analyse approfondie du patrimoine\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.web_researcher = WebResearcher(config)
        self.risk_analyzer = RiskAnalyzer(config)
        self.recommender = Recommender(config)
        self.stress_tester = StressTester(config)
        
    def analyze(self, input_data: dict) -> dict:
        \"\"\"Point d'entr√©e principal d'analyse\"\"\"
        self.logger.info("D√©but analyse...")
        
        start_time = datetime.now()
        
        analysis = {
            "meta": {
                "version": "1.0.0",
                "generated_at": datetime.now().isoformat(),
                "analysis_duration_seconds": 0,
                "web_searches_count": 0
            },
            "synthese": {},
            "repartition": {},
            "risques": {},
            "recommandations": {},
            "stress_tests": [],
            "recherches_web": []
        }
        
        # 1. Calcul r√©partitions
        self.logger.info("Analyse r√©partition...")
        analysis["repartition"] = self._analyze_repartition(input_data)
        
        # 2. Identification risques (avec web research)
        self.logger.info("Identification risques...")
        analysis["risques"] = self.risk_analyzer.analyze(input_data, self.web_researcher)
        
        # 3. G√©n√©ration recommandations
        self.logger.info("G√©n√©ration recommandations...")
        analysis["recommandations"] = self.recommender.generate(input_data, analysis["risques"])
        
        # 4. Stress tests
        self.logger.info("Ex√©cution stress tests...")
        analysis["stress_tests"] = self.stress_tester.run_all_tests(input_data)
        
        # 5. Synth√®se
        self.logger.info("G√©n√©ration synth√®se globale...")
        analysis["synthese"] = self._generate_synthese(analysis, input_data)
        
        # 6. M√©tadonn√©es
        analysis["recherches_web"] = self.web_researcher.get_history()
        analysis["meta"]["web_searches_count"] = len(analysis["recherches_web"])
        analysis["meta"]["analysis_duration_seconds"] = int((datetime.now() - start_time).total_seconds())
        
        # Sauvegarde
        output_path = Path(self.config["paths"]["generated"]) / self.config["analyzer"]["output_file"]
        self.logger.info(f"Sauvegarde {output_path}...")
        self._save_json(analysis, output_path)
        
        self.logger.info("‚úì Analyse termin√©e")
        return analysis
    
    def _analyze_repartition(self, data: dict) -> dict:
        \"\"\"Analyse la r√©partition du patrimoine\"\"\"
        repartition = {
            "par_etablissement": [],
            "par_classe_actifs": [],
            "concentration": {}
        }
        
        # PLACEHOLDER: Impl√©menter analyse r√©partition
        
        return repartition
    
    def _generate_synthese(self, analysis: dict, input_data: dict) -> dict:
        \"\"\"G√©n√®re la synth√®se globale\"\"\"
        synthese = {
            "patrimoine_total": 0,
            "patrimoine_financier": 0,
            "patrimoine_immobilier": 0,
            "score_global": 7.5,
            "scores_details": {
                "diversification": 8,
                "resilience": 7.5,
                "liquidite": 6.5,
                "fiscalite": 7,
                "croissance": 8.5
            },
            "risque_principal": "√Ä d√©finir",
            "priorites": "√Ä d√©finir"
        }
        
        return synthese
    
    def _save_json(self, data: dict, output_path: Path):
        \"\"\"Sauvegarde le JSON d'analyse\"\"\"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
""")

    # 10. tools/generator.py
    print("üõ†Ô∏è  Cr√©ation tools/generator.py...")
    create_file("tools/generator.py", """\"\"\"
Module de g√©n√©ration du rapport HTML
\"\"\"

import json
import logging
from pathlib import Path
from bs4 import BeautifulSoup


class ReportGenerator:
    \"\"\"G√©n√®re le rapport HTML depuis l'analyse\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def generate(self, analysis_data: dict, timestamp: str) -> str:
        \"\"\"G√©n√®re le rapport HTML\"\"\"
        self.logger.info("D√©but g√©n√©ration HTML...")
        
        # 1. Load template
        self.logger.info("Chargement template...")
        template_path = Path(self.config["paths"]["templates"]) / self.config["generator"]["template_file"]
        
        if not template_path.exists():
            raise FileNotFoundError(f"Template introuvable : {template_path}")
        
        template_html = template_path.read_text(encoding='utf-8')
        soup = BeautifulSoup(template_html, 'lxml')
        
        # 2. Inject simple fields
        self.logger.info("Injection donn√©es...")
        self._inject_simple_fields(soup, analysis_data)
        
        # 3. Inject repeated rows
        self._inject_repeated_rows(soup, analysis_data)
        
        # 4. Inject chart data
        self._inject_chart_data(soup, analysis_data)
        
        # 5. Save with timestamp
        output_filename = f"{self.config['generator']['output_prefix']}{timestamp}.html"
        output_path = Path(self.config["paths"]["generated"]) / output_filename
        
        self.logger.info(f"Sauvegarde {output_path}...")
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(str(soup), encoding='utf-8')
        
        self.logger.info("‚úì G√©n√©ration termin√©e")
        return str(output_path)
    
    def _inject_simple_fields(self, soup, data):
        \"\"\"Injecte les champs simples [data-field]\"\"\"
        # PLACEHOLDER: Impl√©menter injection
        pass
    
    def _inject_repeated_rows(self, soup, data):
        \"\"\"Duplique et remplit les lignes de tableaux\"\"\"
        # PLACEHOLDER: Impl√©menter duplication
        pass
    
    def _inject_chart_data(self, soup, data):
        \"\"\"Injecte les donn√©es dans le graphique Chart.js\"\"\"
        # PLACEHOLDER: Impl√©menter injection graphique
        pass
    
    def _format_currency(self, value: float) -> str:
        \"\"\"Formate un montant en euros\"\"\"
        return f"{value:,.0f} ‚Ç¨".replace(",", " ")
""")

    # 11. tools/utils/file_parser.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/file_parser.py...")
    create_file("tools/utils/file_parser.py", """\"\"\"
Module de parsing de fichiers sources
\"\"\"

import pandas as pd
import pdfplumber
import json
import logging
from typing import Dict, Any


class FileParser:
    \"\"\"Parser g√©n√©rique pour CSV, PDF, JSON\"\"\"
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def parse_csv(self, filepath: str) -> pd.DataFrame:
        \"\"\"Parse un fichier CSV\"\"\"
        try:
            df = pd.read_csv(
                filepath,
                encoding='utf-8-sig',
                sep=None,
                engine='python'
            )
            
            # Nettoyage colonnes
            df.columns = df.columns.str.strip().str.lower()
            
            self.logger.info(f"CSV pars√© : {filepath} ({len(df)} lignes)")
            return df
            
        except Exception as e:
            self.logger.error(f"Erreur parsing CSV {filepath}: {e}")
            raise
            
    def parse_pdf(self, filepath: str) -> Dict[str, Any]:
        \"\"\"Parse un fichier PDF\"\"\"
        try:
            result = {
                "metadata": {},
                "tables": [],
                "text": ""
            }
            
            with pdfplumber.open(filepath) as pdf:
                result["metadata"]["pages"] = len(pdf.pages)
                
                for i, page in enumerate(pdf.pages):
                    tables = page.extract_tables()
                    for table in tables:
                        if table:
                            result["tables"].append({
                                "page": i + 1,
                                "data": table
                            })
                    
                    result["text"] += page.extract_text() or ""
            
            self.logger.info(f"PDF pars√© : {filepath} ({result['metadata']['pages']} pages)")
            return result
            
        except Exception as e:
            self.logger.error(f"Erreur parsing PDF {filepath}: {e}")
            raise
            
    def parse_json(self, filepath: str) -> Dict[str, Any]:
        \"\"\"Parse un fichier JSON\"\"\"
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.logger.info(f"JSON pars√© : {filepath}")
            return data
            
        except Exception as e:
            self.logger.error(f"Erreur parsing JSON {filepath}: {e}")
            raise
""")

    # 12. tools/utils/web_research.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/web_research.py...")
    create_file("tools/utils/web_research.py", """\"\"\"
Module de recherche web via Anthropic API
\"\"\"

import anthropic
import logging
import time
from typing import List, Dict, Any
from datetime import datetime


class WebResearcher:
    \"\"\"G√®re les recherches web avec citation des sources\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.client = anthropic.Anthropic()
        self.history = []
        self.max_retries = config.get("analyzer", {}).get("web_research", {}).get("retry_count", 3)
        
    def search(self, sujet: str, queries: List[str], context: str = "") -> List[Dict[str, Any]]:
        \"\"\"Effectue plusieurs recherches web sur un sujet\"\"\"
        self.logger.info(f"Recherches sur : {sujet}")
        all_sources = []
        
        for i, query in enumerate(queries):
            self.logger.info(f"[{i+1}/{len(queries)}] Recherche : '{query}'")
            
            sources = self._search_single(query, context)
            all_sources.extend(sources)
            
            self.history.append({
                "sujet": sujet,
                "query": query,
                "date": datetime.now().isoformat(),
                "sources_found": len(sources)
            })
            
            self.logger.debug(f"‚Üí {len(sources)} sources trouv√©es")
            time.sleep(1)  # Rate limiting
        
        # D√©doublonnage
        unique_sources = []
        seen_urls = set()
        for source in all_sources:
            if source.get("url") and source["url"] not in seen_urls:
                unique_sources.append(source)
                seen_urls.add(source["url"])
        
        return unique_sources
        
    def _search_single(self, query: str, context: str = "") -> List[Dict[str, Any]]:
        \"\"\"Effectue une recherche web unique\"\"\"
        # PLACEHOLDER: Impl√©menter recherche avec API Anthropic
        # Pour l'instant, retourne un placeholder
        return [{
            "url": "https://example.com",
            "titre": "Source placeholder",
            "extrait": "√Ä impl√©menter avec API Anthropic",
            "pertinence": "Moyenne",
            "date_acces": datetime.now().strftime("%Y-%m-%d")
        }]
        
    def get_history(self) -> List[Dict[str, Any]]:
        \"\"\"Retourne l'historique des recherches\"\"\"
        return self.history
""")

    # 13. tools/utils/risk_analyzer.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/risk_analyzer.py...")
    create_file("tools/utils/risk_analyzer.py", """\"\"\"
Module d'analyse des risques patrimoniaux
\"\"\"

import logging
from typing import Dict, List


class RiskAnalyzer:
    \"\"\"Analyse tous types de risques\"\"\"
    
    SEUILS = {
        "concentration_etablissement_critique": 50,
        "concentration_etablissement_eleve": 30,
        "concentration_juridiction_critique": 80,
        "concentration_juridiction_eleve": 60,
        "liquidite_critique": 5000,
        "liquidite_faible": 15000
    }
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Override seuils depuis config
        config_thresholds = config.get("analyzer", {}).get("risk_thresholds", {})
        self.SEUILS.update(config_thresholds)
        
    def analyze(self, data: dict, web_researcher) -> Dict[str, List[Dict]]:
        \"\"\"Analyse compl√®te de tous risques\"\"\"
        self.logger.info("Analyse des risques...")
        
        risques = {
            "critiques": [],
            "eleves": [],
            "moyens": [],
            "faibles": []
        }
        
        # PLACEHOLDER: Impl√©menter analyse risques
        self.logger.info(f"‚úì {len(risques['critiques'])} risques critiques identifi√©s")
        
        return risques
""")

    # 14. tools/utils/recommendations.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/recommendations.py...")
    create_file("tools/utils/recommendations.py", """\"\"\"
Module de g√©n√©ration de recommandations
\"\"\"

import logging
from typing import Dict, List


class Recommender:
    \"\"\"G√©n√®re recommandations prioritis√©es\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def generate(self, data: dict, risques: dict) -> Dict[str, List[Dict]]:
        \"\"\"G√©n√®re recommandations prioritis√©es\"\"\"
        self.logger.info("G√©n√©ration recommandations...")
        
        recommandations = {
            "prioritaires": [],
            "secondaires": [],
            "long_terme": []
        }
        
        # PLACEHOLDER: Impl√©menter g√©n√©ration recommandations
        self.logger.info(f"‚úì {len(recommandations['prioritaires'])} recommandations prioritaires")
        
        return recommandations
""")

    # 15. tools/utils/stress_tester.py
    print("üõ†Ô∏è  Cr√©ation tools/utils/stress_tester.py...")
    create_file("tools/utils/stress_tester.py", """\"\"\"
Module de simulation de stress tests
\"\"\"

import logging
from typing import Dict, List


class StressTester:
    \"\"\"Simule l'impact de sc√©narios de crise\"\"\"
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
    def run_all_tests(self, data: dict) -> List[Dict]:
        \"\"\"Ex√©cute tous les stress tests\"\"\"
        self.logger.info("Ex√©cution stress tests...")
        
        tests = []
        
        # PLACEHOLDER: Impl√©menter stress tests
        self.logger.info(f"‚úì {len(tests)} sc√©narios simul√©s")
        
        return tests
""")

    # 16. main.py
    print("üöÄ Cr√©ation main.py...")
    create_file("main.py", """#!/usr/bin/env python3
\"\"\"
Patrimoine Analyzer - Point d'entr√©e principal
\"\"\"

import sys
import logging
from pathlib import Path
from datetime import datetime
import yaml
import time

from tools.normalizer import PatrimoineNormalizer
from tools.analyzer import PatrimoineAnalyzer
from tools.generator import ReportGenerator


def setup_logging(log_file: str):
    \"\"\"Configure le syst√®me de logging\"\"\"
    Path("logs").mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] %(levelname)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger(__name__)


def load_config() -> dict:
    \"\"\"Charge la configuration\"\"\"
    config_path = Path("config/config.yaml")
    
    if not config_path.exists():
        raise FileNotFoundError(f"Fichier de configuration introuvable : {config_path}")
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def print_banner():
    \"\"\"Affiche la banni√®re\"\"\"
    banner = \"\"\"
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë     PATRIMOINE ANALYZER v1.0.0                ‚ïë
‚ïë     Rapport patrimonial automatis√©            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    \"\"\"
    print(banner)


def format_duration(seconds: float) -> str:
    \"\"\"Formate une dur√©e\"\"\"
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}m {secs}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h {minutes}m"


def main():
    \"\"\"Fonction principale\"\"\"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = f"logs/rapport_{timestamp}.log"
    
    logger = setup_logging(log_file)
    print_banner()
    
    start_time = time.time()
    
    try:
        # Chargement configuration
        logger.info("Chargement configuration...")
        config = load_config()
        
        # √âTAPE 1 : NORMALISATION
        print(f"\\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üì• √âtape 1/3 : Normalisation")
        step1_start = time.time()
        
        normalizer = PatrimoineNormalizer(config)
        patrimoine_input = normalizer.normalize()
        
        step1_duration = time.time() - step1_start
        print(f"  ‚è±Ô∏è  Dur√©e : {step1_duration:.1f}s")
        
        # √âTAPE 2 : ANALYSE
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üîç √âtape 2/3 : Analyse approfondie")
        step2_start = time.time()
        
        analyzer = PatrimoineAnalyzer(config)
        patrimoine_analysis = analyzer.analyze(patrimoine_input)
        
        step2_duration = time.time() - step2_start
        print(f"  ‚è±Ô∏è  Dur√©e : {format_duration(step2_duration)}")
        
        # √âTAPE 3 : G√âN√âRATION
        print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üìÑ √âtape 3/3 : G√©n√©ration rapport HTML")
        step3_start = time.time()
        
        generator = ReportGenerator(config)
        rapport_path = generator.generate(patrimoine_analysis, timestamp)
        
        step3_duration = time.time() - step3_start
        print(f"  ‚è±Ô∏è  Dur√©e : {step3_duration:.1f}s")
        
        # R√âSUM√â
        total_duration = time.time() - start_time
        
        summary = f\"\"\"
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ‚úÖ RAPPORT G√âN√âR√â AVEC SUCC√àS                ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  üìä Patrimoine total : {patrimoine_analysis['synthese']['patrimoine_total']:,.0f} ‚Ç¨              ‚ïë
‚ïë  ‚ö†Ô∏è  Risques critiques : {len(patrimoine_analysis['risques']['critiques'])}                    ‚ïë
‚ïë  üí° Recommandations : {len(patrimoine_analysis['recommandations']['prioritaires'])}                       ‚ïë
‚ïë  üìÅ Fichier : {Path(rapport_path).name:<30} ‚ïë
‚ïë  üìã Log : {log_file:<38} ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚è±Ô∏è  Dur√©e totale : {format_duration(total_duration)}
        \"\"\"
        print(summary)
        
        logger.info("=" * 60)
        logger.info("EX√âCUTION TERMIN√âE AVEC SUCC√àS")
        logger.info("=" * 60)
        
        return 0
        
    except FileNotFoundError as e:
        logger.error(f"‚ùå Fichier introuvable : {e}")
        return 1
        
    except Exception as e:
        logger.error(f"‚ùå Erreur inattendue : {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
""")

    # 17. README.md
    print("üìö Cr√©ation README.md...")
    create_file("README.md", """# üìä Patrimoine Analyzer

G√©n√©rateur automatis√© de rapports patrimoniaux professionnels avec analyse approfondie et recherches web.

## üéØ Objectif

Transformer vos fichiers sources (CSV, PDF, Markdown) en un rapport patrimonial complet avec :
- ‚úÖ Analyse d√©taill√©e de la r√©partition des actifs
- ‚úÖ Identification des risques (concentration, r√©glementaire, fiscal, march√©)
- ‚úÖ Recommandations prioritis√©es et actionnables
- ‚úÖ Stress tests (crise bancaire, krach, perte emploi...)
- ‚úÖ Recherches web exhaustives avec sources cit√©es
- ‚úÖ Rapport HTML premium professionnel

## üöÄ Installation

### Pr√©requis
- Python 3.10 ou sup√©rieur
- Cl√© API Anthropic (pour recherches web)

### Installation

```bash
# Installation des packages Python
pip install -r requirements.txt

# Configuration API Anthropic
export ANTHROPIC_API_KEY="votre-cl√©-api"
```

## üìÅ Structure du projet

```
patrimoine-analyzer/
‚îú‚îÄ‚îÄ sources/              # üì• VOS fichiers sources (patrimoine.md, CSV, PDF)
‚îú‚îÄ‚îÄ templates/            # üìÑ Template HTML (modifiable)
‚îú‚îÄ‚îÄ generated/            # üì§ Rapports g√©n√©r√©s (automatique)
‚îú‚îÄ‚îÄ logs/                 # üìã Logs d'ex√©cution (automatique)
‚îú‚îÄ‚îÄ tools/                # üõ†Ô∏è Scripts Python
‚îú‚îÄ‚îÄ config/               # ‚öôÔ∏è Configuration
‚îî‚îÄ‚îÄ main.py               # üöÄ Point d'entr√©e
```

## üìù Utilisation

### 1. Pr√©parer les sources

Placez vos fichiers dans `sources/` :

```
sources/
‚îú‚îÄ‚îÄ patrimoine.md         # Point d'entr√©e principal
‚îú‚îÄ‚îÄ [CA] - PEA.csv
‚îú‚îÄ‚îÄ [CA] - AV.pdf
‚îî‚îÄ‚îÄ ... (autres fichiers)
```

### 2. G√©n√©rer le rapport

```bash
python main.py
```

### 3. Consulter le rapport

Ouvrez le fichier g√©n√©r√© :
```
generated/rapport_20251021_143330.html
```

## ‚öôÔ∏è Configuration

Modifiez `config/config.yaml` pour ajuster :
- Seuils de risques
- Nombre max de recherches web
- Chemins de fichiers
- Format de dates

## üé® Personnalisation du template

Le template HTML (`templates/rapport_template.html`) est **modifiable librement** :
- Ajustez les couleurs (variables CSS)
- Modifiez la mise en page
- Ajoutez/supprimez des sections

‚ö†Ô∏è **Important** : Conservez les attributs `data-field` et `data-repeat` pour l'injection de donn√©es.

## üìà Historique des rapports

Tous les rapports sont conserv√©s avec horodatage :
```
generated/
‚îú‚îÄ‚îÄ rapport_20251021_143330.html
‚îú‚îÄ‚îÄ rapport_20251020_091544.html
‚îî‚îÄ‚îÄ rapport_20251015_164522.html
```

## üîç R√©solution de probl√®mes

### Erreur "Fichier introuvable"
- V√©rifiez que `patrimoine.md` existe dans `sources/`
- V√©rifiez que tous les fichiers r√©f√©renc√©s existent

### Erreur "API timeout"
- Connexion internet instable
- Le script retry automatiquement 3√ó

### Rapport incomplet
- Consultez `logs/rapport_YYYYMMDD_HHMMSS.log`

## üìÑ Licence

Usage personnel uniquement. Tous droits r√©serv√©s.

---

**Version** : 1.0.0  
**Derni√®re mise √† jour** : Octobre 2025
""")

    # 18. Message final
    print("\n" + "="*60)
    print("‚úÖ PROJET G√âN√âR√â AVEC SUCC√àS !")
    print("="*60)
    print("\nüì¶ Prochaines √©tapes :")
    print("  1. cd patrimoine-analyzer")
    print("  2. pip install -r requirements.txt")
    print("  3. export ANTHROPIC_API_KEY='votre-cl√©'")
    print("  4. Placez vos fichiers dans sources/")
    print("  5. Placez rapport_template.html dans templates/")
    print("  6. python main.py")
    print("\nüí° Consultez README.md pour plus d'informations")
    print("="*60 + "\n")


if __name__ == "__main__":
    # Cr√©er dossier parent
    project_dir = Path("patrimoine-analyzer")
    
    if project_dir.exists():
        response = input(f"\n‚ö†Ô∏è  Le dossier '{project_dir}' existe d√©j√†. √âcraser ? (o/N) : ")
        if response.lower() != 'o':
            print("‚ùå G√©n√©ration annul√©e")
            exit(0)
    
    project_dir.mkdir(exist_ok=True)
    
    # Changer dans le r√©pertoire du projet
    import os
    os.chdir(project_dir)
    
    # G√©n√©rer le projet
    generate_project()
